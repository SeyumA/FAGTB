{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FAGTB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEO8bqKIzUJUmdbzCMjFDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincent-grari/FAGTB/blob/master/FAGTB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmKbXdtm_BvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "58044b43-7a5a-4bdc-9391-c61e59c13340"
      },
      "source": [
        "!pip3 install fairness\n",
        "!git clone https://github.com/vincent-grari/FAGTB"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairness\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d0/038541647d46112174ae8f9d7ef256d73cfccc0668923748826a0d4cb63c/fairness-0.1.8-py3-none-any.whl (14.2MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2MB 275kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fairness) (2018.9)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from fairness) (1.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from fairness) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from fairness) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from fairness) (1.12.0)\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.29.0 in /usr/local/lib/python3.6/dist-packages (from fairness) (0.34.2)\n",
            "Collecting BlackBoxAuditing>=0.1.26ggplot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/2e/e2e7166bc78eb599b602ca79ace1ceba2ef83b69a0b708c9a7eb729347bf/BlackBoxAuditing-0.1.54.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from fairness) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from fairness) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->fairness) (1.18.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->fairness) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing>=0.1.26ggplot->fairness) (2.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing>=0.1.26ggplot->fairness) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.1->fairness) (0.15.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->BlackBoxAuditing>=0.1.26ggplot->fairness) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing>=0.1.26ggplot->fairness) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing>=0.1.26ggplot->fairness) (0.10.0)\n",
            "Building wheels for collected packages: fire, BlackBoxAuditing\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=8961a3b7140c2affe1030c3be1e11d9a86a5873b022e424ea990ddcc7a1edd3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394767 sha256=8be4e532a9378ae5f7aec67570a6fc9da38fd2593530ebc6308823c4e68369fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/82/7b/ac2a79b8caf97e15ed415162a7f272cbba1e2e2c851fa76ae3\n",
            "Successfully built fire BlackBoxAuditing\n",
            "Installing collected packages: fire, BlackBoxAuditing, fairness\n",
            "Successfully installed BlackBoxAuditing-0.1.54 fairness-0.1.8 fire-0.3.1\n",
            "Cloning into 'FAGTB'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 30 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8t15SobVx31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2b68ce29-0e84-4efa-d6c9-ebcb08201c09"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://grari.fr/Fairness/ProcessedData.py', '/usr/local/lib/python3.6/dist-packages/fairness/data/objects/ProcessedData.py')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/usr/local/lib/python3.6/dist-packages/fairness/data/objects/ProcessedData.py',\n",
              " <http.client.HTTPMessage at 0x7fe8c90bec18>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNxgkEwlE0-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "2d955b7e-7e98-4bc9-8ef8-135164ccb895"
      },
      "source": [
        "import fire\n",
        "import os\n",
        "import statistics\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from fairness import results\n",
        "from fairness.data.objects.list import DATASETS, get_dataset_names\n",
        "from fairness.data.objects.ProcessedData import ProcessedData\n",
        "from fairness.benchmark import run_alg\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from fairness.algorithms.zafar.ZafarAlgorithm import ZafarAlgorithmBaseline, ZafarAlgorithmAccuracy, ZafarAlgorithmFairness\n",
        "from fairness.algorithms.kamishima.KamishimaAlgorithm import KamishimaAlgorithm\n",
        "from fairness.algorithms.kamishima.CaldersAlgorithm import CaldersAlgorithm\n",
        "from fairness.algorithms.feldman.FeldmanAlgorithm import FeldmanAlgorithm\n",
        "from fairness.algorithms.baseline.SVM import SVM\n",
        "from fairness.algorithms.baseline.DecisionTree import DecisionTree\n",
        "from fairness.algorithms.baseline.GaussianNB import GaussianNB\n",
        "from fairness.algorithms.baseline.LogisticRegression import LogisticRegression\n",
        "from fairness.algorithms.ParamGridSearch import ParamGridSearch\n",
        "from fairness.algorithms.Ben.SDBSVM import SDBSVM\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def p_rule(y_pred, z_values, threshold=0.5):\n",
        "    y_z_1 = y_pred[z_values == 1] > threshold if threshold else y_pred[z_values == 1]\n",
        "    y_z_0 = y_pred[z_values == 0] > threshold if threshold else y_pred[z_values == 0]\n",
        "    odds = y_z_1.mean() / y_z_0.mean()\n",
        "    return np.min([odds, 1/odds]) * 100\n",
        "\n",
        "class Sigmoid():\n",
        "    def __call__(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    def gradient(self, x):\n",
        "        return self.__call__(x) * (1 - self.__call__(x))\n",
        "\n",
        "def DispFNR(y_pred, y, z_values, threshold=0.5):\n",
        "    ypred_z_1 = y_pred > threshold if threshold else y_pred[z_values == 1]\n",
        "    ypred_z_0 = y_pred > threshold if threshold else y_pred[z_values == 0]\n",
        "    result=abs(ypred_z_1[(y==1) & (z_values==0)].mean()-ypred_z_1[(y==1) & (z_values==1)].mean())\n",
        "    return result\n",
        "\n",
        "def DispFPR(y_pred, y, z_values, threshold=0.5):\n",
        "    ypred_z_1 = y_pred > threshold if threshold else y_pred[z_values == 1]\n",
        "    ypred_z_0 = y_pred > threshold if threshold else y_pred[z_values == 0]\n",
        "    result=abs(ypred_z_1[(y==0) & (z_values==0)].mean()-ypred_z_1[(y==0) & (z_values==1)].mean())\n",
        "    return result\n",
        "\n",
        "def DI(y_pred, z_values, threshold=0.5):\n",
        "    y_z_1 = y_pred[z_values == 1] > threshold if threshold else y_pred[z_values == 1]\n",
        "    y_z_0 = y_pred[z_values == 0] > threshold if threshold else y_pred[z_values == 0]\n",
        "    odds = abs(y_z_1.mean() - y_z_0.mean())\n",
        "    return odds\n",
        "\n",
        "def display_results(y_pred, y, sensitive):\n",
        "    y_pred2 = (y_pred>0.5).astype(int)\n",
        "    accuracy = accuracy_score(y, np.squeeze(y_pred2))\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"PRULE : \", p_rule(y_pred,sensitive))\n",
        "    print(\"DI : \", DI(y_pred, sensitive))\n",
        "    print(\"DispFPR : \", DispFPR(y_pred2, y, sensitive))\n",
        "    print(\"DispFNR : \", DispFNR(y_pred2, y, sensitive))\n",
        "    return {'Accuracy': accuracy, 'PRULE': p_rule(y_pred,sensitive), 'DispFPR': DispFPR(y_pred2, y, sensitive)\n",
        "            ,'DispFNR': DispFNR(y_pred2, y, sensitive)}\n",
        "\n",
        "def DATA_TRAIN_TEST(num,sens,y,columns_delete):\n",
        "    dataset = DATASETS[num] # Adult data set\n",
        "    all_sensitive_attributes = dataset.get_sensitive_attributes_with_joint()\n",
        "    ProcessedData(dataset)\n",
        "    processed_dataset = ProcessedData(dataset)\n",
        "    train_test_splits = processed_dataset.create_train_test_splits(1)\n",
        "    train_test_splits.keys()\n",
        "    train, test = train_test_splits['numerical-binsensitive'][0]\n",
        "    X_train = train\n",
        "    X_test = test\n",
        "    sensitive =  train[sens].values\n",
        "    sensitivet =  test[sens].values\n",
        "    y_train = train[y]\n",
        "    y_test = test[y]\n",
        "    \n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    s=X_train[sens]\n",
        "    st=X_test[sens]\n",
        "    t=X_train[y]\n",
        "    tt=X_test[y]\n",
        "    scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
        "    X_train = X_train.pipe(scale_df, scaler)\n",
        "    X_test = X_test.pipe(scale_df, scaler)\n",
        "    X_train= X_train.drop([sens,y], axis=1)\n",
        "    X_train[sens] = s\n",
        "    X_train[y] = t\n",
        "    X_test= X_test.drop([sens,y], axis=1)\n",
        "    X_test[sens] = st\n",
        "    X_test[y] = tt\n",
        "\n",
        "    X_train = X_train.drop(columns_delete,1)\n",
        "    X_test = X_test.drop(columns_delete,1)\n",
        "    return X_train, X_test, y_train, y_test, sensitive, sensitivet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available algorithms:\n",
            "  SVM\n",
            "  GaussianNB\n",
            "  LR\n",
            "  DecisionTree\n",
            "  Kamishima\n",
            "  Calders\n",
            "  ZafarBaseline\n",
            "  ZafarFairness\n",
            "  ZafarAccuracy\n",
            "  Kamishima-accuracy\n",
            "  Kamishima-DIavgall\n",
            "  Feldman-SVM\n",
            "  Feldman-GaussianNB\n",
            "  Feldman-LR\n",
            "  Feldman-DecisionTree\n",
            "  Feldman-SVM-DIavgall\n",
            "  Feldman-SVM-accuracy\n",
            "  Feldman-GaussianNB-DIavgall\n",
            "  Feldman-GaussianNB-accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc9BzZv7FFHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c41ac18f-80b9-4d5e-8040-e4c42beedeef"
      },
      "source": [
        "    import numpy as np\n",
        "    from sklearn.tree import DecisionTreeRegressor\n",
        "    from sklearn.utils import shuffle\n",
        "    from torch.autograd import Variable\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    import tensorflow.compat.v1 as tf\n",
        "    tf.disable_v2_behavior() \n",
        "    \n",
        "    def p_rule(y_pred, z_values, threshold=0.5):\n",
        "        y_z_1 = y_pred[z_values == 1] > threshold if threshold else y_pred[z_values == 1]\n",
        "        y_z_0 = y_pred[z_values == 0] > threshold if threshold else y_pred[z_values == 0]\n",
        "        odds = y_z_1.mean() / y_z_0.mean()\n",
        "        return np.min([odds, 1/odds]) * 100\n",
        "    \n",
        "    def lossgr(y, p):\n",
        "        # Avoid division by zero\n",
        "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
        "        return - y * np.log(p) - (1 - y) * np.log(1 - p)\n",
        "    \n",
        "    class FAGTB(object):\n",
        "    \n",
        "        def __init__(self, n_estimators, learning_rate, min_samples_split,\n",
        "                     min_impurity, max_depth, max_features, regression):\n",
        "            self.n_estimators = n_estimators\n",
        "            self.learning_rate = learning_rate\n",
        "            self.min_samples_split = min_samples_split\n",
        "            self.min_impurity = min_impurity\n",
        "            self.max_depth = max_depth\n",
        "            self.regression = regression\n",
        "            self.max_features = max_features\n",
        "    \n",
        "            # Initialize regression trees\n",
        "            self.trees = []\n",
        "            self.clfs = []\n",
        "            self.lossfunction_adv =[]\n",
        "            self.losstraining =[]\n",
        "    \n",
        "            for _ in range(n_estimators):\n",
        "                tree = DecisionTreeRegressor(criterion='friedman_mse', max_depth=9,\n",
        "      max_features=self.max_features, max_leaf_nodes=None,\n",
        "      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "      min_samples_leaf=1, min_samples_split=2,\n",
        "      min_weight_fraction_leaf=0.0\n",
        "      , random_state=0)\n",
        "                self.trees.append(tree)\n",
        "                clf = LogisticRegression()           \n",
        "                self.clfs.append(clf)\n",
        "                self.model = []\n",
        "        def fit2(self, X, y, sensitive, LAMBDA):\n",
        "            clf = LogisticRegression()\n",
        "            clf._initialize_parameters(sensitive)\n",
        "            print(clf.param)\n",
        "    \n",
        "        def gradient(self, y, p):\n",
        "            # Avoid division by zero\n",
        "            p = np.clip(p, 1e-15, 1 - 1e-15)\n",
        "            return - (y / p) + (1 - y) / (1 - p)\n",
        "    \n",
        "        def fit(self, X, y, sensitive, LAMBDA, Xtest, yt, sensitivet):\n",
        "    \n",
        "            y2 = np.expand_dims(sensitive, axis=1)\n",
        "    \n",
        "            lfadv =0\n",
        "    \n",
        "            self.Init = np.log(np.sum(y)/np.sum(1-y))\n",
        "            \n",
        "            y_pred2 = np.full(np.shape(y), self.Init)\n",
        "            y_pred = np.full(np.shape(y), self.Init)\n",
        "            y_predt = np.full(np.shape(yt), self.Init)\n",
        "            t =np.full(np.shape(y), 0)\n",
        "            t2 =np.full(np.shape(yt), 0)\n",
        "            self.LAMBDA = LAMBDA\n",
        "            proj = 0\n",
        "            table = [0,0,0,0]\n",
        "            y_pred2 = np.expand_dims(1/(1+np.exp(-y_pred)), axis=1)\n",
        "    \n",
        "            graph = tf.Graph()\n",
        "            seed = 7 # for reproducible purpose\n",
        "            input_size =  1 # number of features\n",
        "\n",
        "            learning_rate2 = 0.01\n",
        "            with graph.as_default():\n",
        "\n",
        "                X_input = tf.placeholder(dtype=tf.float32, shape=[None, input_size], name='X_input')\n",
        "                y_input = tf.placeholder(dtype=tf.float32, shape=[None, 1], name='y_input')\n",
        "                \n",
        "                W1 = tf.Variable(tf.random_normal(shape=[input_size, 1], seed=seed), name='W1', trainable=True)\n",
        "                b1 = tf.Variable(tf.random_normal(shape=[1], seed=seed), name='b1', trainable=True)\n",
        "                sigm = tf.nn.sigmoid(tf.add(tf.matmul(X_input, W1), b1), name='pred')\n",
        "                logit = tf.add(tf.matmul(X_input, W1), b1)\n",
        "                loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_input,\n",
        "                                                                        logits=logit, name='loss'))\n",
        "                train_steps = tf.train.GradientDescentOptimizer(learning_rate2).minimize(loss)\n",
        "            \n",
        "                sigm2 = tf.cast(sigm, tf.float32, name='sigm2') # 1 if >= 0.5\n",
        "                pred = tf.cast(tf.greater_equal(sigm, 0.5), tf.float32, name='pred') # 1 if >= 0.5\n",
        "                acc = tf.reduce_mean(tf.cast(tf.equal(pred, y_input), tf.float32), name='acc')\n",
        "                \n",
        "                init_var = tf.global_variables_initializer()\n",
        "                var_grad = tf.gradients(loss, X_input)[0]\n",
        "                \n",
        "            train_feed_dict = {X_input: y_pred2, y_input: y2}\n",
        "    \n",
        "            sess = tf.Session(graph=graph)\n",
        "            sess.run(init_var)\n",
        "            \n",
        "    \n",
        "            for i in range(self.n_estimators):\n",
        "\n",
        "                y_pred2 = np.expand_dims(1/(1+np.exp(-y_pred)), axis=1)\n",
        "\n",
        "                train_feed_dict = {X_input: y_pred2, y_input: y2}   \n",
        "                sess.run(train_steps, feed_dict=train_feed_dict)\n",
        "                cur_loss = sess.run(loss, feed_dict=train_feed_dict)\n",
        "                train_acc = sess.run(acc, feed_dict=train_feed_dict)\n",
        "                S_ADV = sess.run(sigm2, feed_dict=train_feed_dict)\n",
        "\n",
        "                gradient_adv = sess.run(var_grad, feed_dict=train_feed_dict)\n",
        "                                \n",
        "                if abs(np.sum(gradient_adv)) <0.001 :\n",
        "                     print('erreur de gradient')\n",
        "\n",
        "                lfadv = gradient_adv*y_pred2*(1-y_pred2)    # *len(gradient_adv)       \n",
        "\n",
        "                t=-np.squeeze(lfadv.T)\n",
        "                proj = 0\n",
        "                gradient = y- 1/(1+np.exp(-y_pred))- LAMBDA*t -proj\n",
        "                self.trees[i].fit(X, gradient)\n",
        "                update = self.trees[i].predict(X)\n",
        " \n",
        "                y_pred += np.multiply(self.learning_rate, update)\n",
        "                y_fin = 1/(1+np.exp(-y_pred))\n",
        "    \n",
        "                losstraining = lossgr(y,y_fin)\n",
        "                lossglobal = losstraining - LAMBDA*t\n",
        "\n",
        "                updatet = self.trees[i].predict(Xtest)\n",
        "                y_predt += np.multiply(self.learning_rate, updatet) \n",
        "                y_predt2=1/(1+np.exp(-y_predt))\n",
        "                accuracy = accuracy_score(y, np.squeeze(y_fin)>0.5)\n",
        "                accuracyt = accuracy_score(yt, np.squeeze(y_predt2)>0.5)\n",
        "    \n",
        "                if i % 5 == 0:\n",
        "                    print (i,np.sum(lfadv),np.sum(losstraining),np.sum(lossglobal), \"Accuracy:\", round(accuracy,4), \" test : \", round(accuracyt,4), \" Prule Train : \", p_rule(y_fin, sensitive)/100,\" Prule test : \", p_rule(y_predt2, sensitivet)/100)\n",
        "                table = np.vstack([table,[accuracy,accuracyt, p_rule(y_fin, sensitive)/100, p_rule(y_predt2, sensitivet)/100]])\n",
        "            return {'y_pred2':y_pred2,'S_ADV':S_ADV}\n",
        "    \n",
        "        def predict(self, X):\n",
        "            y_pred = np.full(np.shape(X)[0],self.Init, self.Init)\n",
        "    \n",
        "            for i in range(self.n_estimators):\n",
        "                update = self.trees[i].predict(X)\n",
        "                y_pred += np.multiply(self.learning_rate, update)\n",
        "                y_fin = 1/(1+np.exp(-y_pred))\n",
        "            # Set label to the value that maximizes probability\n",
        "            return y_fin\n",
        "       \n",
        "    \n",
        "    class Sigmoid():\n",
        "        def __call__(self, x):\n",
        "            return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "        def gradient(self, x):\n",
        "            return self.__call__(x) * (1 - self.__call__(x))\n",
        "    \n",
        "    \n",
        "    class LogisticRegression():\n",
        "        def __init__(self, learning_rate=.1):\n",
        "            self.param = None\n",
        "            self.learning_rate = learning_rate\n",
        "            self.sigmoid = Sigmoid()\n",
        "    \n",
        "        def _initialize_parameters(self, X):\n",
        "            n_features = np.shape(X)[1]\n",
        "            limit = 1 / math.sqrt(n_features)\n",
        "            self.param = np.random.uniform(-limit, limit, (n_features,))\n",
        "   \n",
        "        def fit(self, X, y, iteration):\n",
        "            y_pred = self.sigmoid(X.dot(self.param))\n",
        "            self.param -= self.learning_rate * -(y - y_pred).dot(X)\n",
        "            return self.param\n",
        "    \n",
        "        def gradient_adv(self,X,y):\n",
        "            y_pred = self.sigmoid(X.dot(self.param))\n",
        "            gradient_adv = (y - y_pred)*self.param*X.T*(1-X).T\n",
        "            return gradient_adv\n",
        "    \n",
        "        def predict(self, X):\n",
        "            y_pred = np.round(self.sigmoid(X.dot(self.param))).astype(int)\n",
        "            return y_pred\n",
        "    \n",
        "        def lossfunction(self,X,y):\n",
        "            y_pred = self.sigmoid(X.dot(self.param))\n",
        "            return lossgr(y,y_pred)\n",
        "        \n",
        "        def lossfunction_adv(self,X,y):\n",
        "            y_pred = self.sigmoid(X.dot(self.param))\n",
        "            return y-y_pred\n",
        "    \n",
        "        def param2(self):\n",
        "            return 2*self.param\n",
        "        "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAlyPoMBXY9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test, sensitive, sensitivet = DATA_TRAIN_TEST(1,'sex',\"income-per-year\",['sex','income-per-year','race-sex']) #,'race','race-sex','sex'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPobtlKhXaLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3dacbb9-4833-45cb-b964-c88ed422578e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24129, 97)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jruLj9ewE9LT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afd08470-b4b0-4bf3-d34c-d6d6d7c415a6"
      },
      "source": [
        "import copy\n",
        "table = [0,0,0,0]\n",
        "\n",
        "for i in range(5):\n",
        "    X_train, X_test, y_train, y_test, sensitive, sensitivet = DATA_TRAIN_TEST(1,'sex',\"income-per-year\",['sex','income-per-year','race-sex']) \n",
        "   \n",
        "    classifier= FAGTB(n_estimators=260, learning_rate = 0.01, max_depth = 10,min_samples_split=1.0, min_impurity =False, max_features =20, regression =1)\n",
        "    y_pred = classifier.fit(X_train.values, y_train.values, sensitive, LAMBDA=0.165, Xtest=X_test.values, yt=y_test,\n",
        "                      sensitivet=sensitivet)\n",
        "    \n",
        "    ##### Results on Test dataset #####\n",
        "    y_predt2 = classifier.predict(X_test.values)\n",
        "    print('')\n",
        "    print('Results on test set :')\n",
        "    Res = display_results(y_predt2, y_test.values, sensitivet)\n",
        "    table = np.vstack([table,[Res['Accuracy']*100,Res['PRULE'],Res['DispFPR'],Res['DispFNR']]])\n",
        "np.savetxt(sys.stdout, np.mean(table[1:,], axis=0).astype(float), '%5.2f')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 16840.437311229914 13548.353916456272 16327.02607280921 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 51513.426354874086 13471.774142130735 21971.48949068496 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 6549.166904111607 13394.132095090543 14474.744634268955 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15 54319.03857410144 13328.21027145063 22290.85163617737 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20 2001.5105146768499 13256.439117158174 13586.688352079853 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25 -520.8646943039514 13185.321800173368 13099.379125613215 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30 57321.622783856765 13120.0929104152 22578.160669751567 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "35 16419.977936492825 13044.406487930264 15753.702847451577 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40 53162.50587072268 12975.316656018902 21747.130124688145 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "45 -212.1351187434203 12907.116856798033 12872.114562205366 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50 44126.76338711449 12832.858225419697 20113.774184293594 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "55 35762.679183159154 12756.826005631196 18657.66807085246 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60 21270.694235143084 12702.67529525275 16212.33984405136 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "65 53796.4520453037 12642.20826702798 21518.62285450309 Accuracy: 0.7502  test :  0.7547  Prule Train :  nan  Prule test :  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-53efb5ae2332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFAGTB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_impurity\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     y_pred = classifier.fit(X_train.values, y_train.values, sensitive, LAMBDA=0.165, Xtest=X_test.values, yt=y_test,\n\u001b[0;32m---> 10\u001b[0;31m                       sensitivet=sensitivet)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m##### Results on Test dataset #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-559b3d6d54c0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensitive, LAMBDA, Xtest, yt, sensitivet)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0my_fin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mlosstraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_fin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mlossglobal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosstraining\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mLAMBDA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-559b3d6d54c0>\u001b[0m in \u001b[0;36mlossgr\u001b[0;34m(y, p)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Avoid division by zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbkV32GfFRB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "40733ac6-921b-4e1b-b47d-4c5e4898f7e4"
      },
      "source": [
        "np.set_printoptions(suppress=True) \n",
        "np.mean(table[1:,], axis=0).astype(float)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c22c944fe072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5othDpTlKYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}